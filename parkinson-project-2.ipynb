{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-15T17:36:48.596987Z","iopub.execute_input":"2023-05-15T17:36:48.597518Z","iopub.status.idle":"2023-05-15T17:36:48.632887Z","shell.execute_reply.started":"2023-05-15T17:36:48.597491Z","shell.execute_reply":"2023-05-15T17:36:48.632033Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/amp-parkinsons-disease-progression-prediction/train_proteins.csv\n/kaggle/input/amp-parkinsons-disease-progression-prediction/train_clinical_data.csv\n/kaggle/input/amp-parkinsons-disease-progression-prediction/public_timeseries_testing_util.py\n/kaggle/input/amp-parkinsons-disease-progression-prediction/supplemental_clinical_data.csv\n/kaggle/input/amp-parkinsons-disease-progression-prediction/train_peptides.csv\n/kaggle/input/amp-parkinsons-disease-progression-prediction/amp_pd_peptide/competition.cpython-37m-x86_64-linux-gnu.so\n/kaggle/input/amp-parkinsons-disease-progression-prediction/amp_pd_peptide/__init__.py\n/kaggle/input/amp-parkinsons-disease-progression-prediction/amp_pd_peptide_310/competition.cpython-310-x86_64-linux-gnu.so\n/kaggle/input/amp-parkinsons-disease-progression-prediction/amp_pd_peptide_310/__init__.py\n/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/sample_submission.csv\n/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test_proteins.csv\n/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test_peptides.csv\n/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Data preparation (as in project1)","metadata":{}},{"cell_type":"code","source":"train_proteins = pd.read_csv(\"/kaggle/input/amp-parkinsons-disease-progression-prediction/train_proteins.csv\")\ntrain_peptides = pd.read_csv(\"/kaggle/input/amp-parkinsons-disease-progression-prediction/train_peptides.csv\")\ntrain_clinical = pd.read_csv(\"/kaggle/input/amp-parkinsons-disease-progression-prediction/train_clinical_data.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-05-15T17:36:48.634526Z","iopub.execute_input":"2023-05-15T17:36:48.634778Z","iopub.status.idle":"2023-05-15T17:36:49.886470Z","shell.execute_reply.started":"2023-05-15T17:36:48.634757Z","shell.execute_reply":"2023-05-15T17:36:49.885517Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_clinical['on_medication'] = train_clinical['upd23b_clinical_state_on_medication'].apply(lambda x: 1 if x=='On' else 0)","metadata":{"execution":{"iopub.status.busy":"2023-05-15T17:36:49.887290Z","iopub.execute_input":"2023-05-15T17:36:49.887868Z","iopub.status.idle":"2023-05-15T17:36:49.898289Z","shell.execute_reply.started":"2023-05-15T17:36:49.887843Z","shell.execute_reply":"2023-05-15T17:36:49.897369Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-05-15T17:36:49.900076Z","iopub.execute_input":"2023-05-15T17:36:49.900313Z","iopub.status.idle":"2023-05-15T17:36:49.908951Z","shell.execute_reply.started":"2023-05-15T17:36:49.900294Z","shell.execute_reply":"2023-05-15T17:36:49.908274Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def prepare_dataset(train_clinical, train_proteins, train_peptides):\n        \n    df_protein_grouped = train_proteins.groupby(['visit_id','UniProt'])['NPX'].mean().reset_index()\n    df_peptide_grouped = train_peptides.groupby(['visit_id','Peptide'])['PeptideAbundance'].mean().reset_index()\n    \n    df_protein = df_protein_grouped.pivot(index='visit_id',columns = 'UniProt', values = 'NPX').rename_axis(columns=None).reset_index()\n    df_peptide = df_peptide_grouped.pivot(index='visit_id',columns = 'Peptide', values = 'PeptideAbundance').rename_axis(columns=None).reset_index()\n    \n    df = train_clinical[['visit_id', 'updrs_1', 'updrs_2', 'updrs_3', 'updrs_4', 'visit_month', 'on_medication']]\n    df = df.merge(df_protein, on=['visit_id'], how='left')\n    df = df.merge(df_peptide, on=['visit_id'], how='left')\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2023-05-15T17:36:49.910183Z","iopub.execute_input":"2023-05-15T17:36:49.910520Z","iopub.status.idle":"2023-05-15T17:36:49.921290Z","shell.execute_reply.started":"2023-05-15T17:36:49.910494Z","shell.execute_reply":"2023-05-15T17:36:49.920014Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df = prepare_dataset(train_clinical, train_proteins, train_peptides)   \ndf","metadata":{"execution":{"iopub.status.busy":"2023-05-15T17:36:49.922072Z","iopub.execute_input":"2023-05-15T17:36:49.922298Z","iopub.status.idle":"2023-05-15T17:36:50.829476Z","shell.execute_reply.started":"2023-05-15T17:36:49.922279Z","shell.execute_reply":"2023-05-15T17:36:50.828379Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"      visit_id  updrs_1  updrs_2  updrs_3  updrs_4  visit_month  \\\n0         55_0     10.0      6.0     15.0      NaN            0   \n1         55_3     10.0      7.0     25.0      NaN            3   \n2         55_6      8.0     10.0     34.0      NaN            6   \n3         55_9      8.0      9.0     30.0      0.0            9   \n4        55_12     10.0     10.0     41.0      0.0           12   \n...        ...      ...      ...      ...      ...          ...   \n2610  65043_48      7.0      6.0     13.0      0.0           48   \n2611  65043_54      4.0      8.0     11.0      1.0           54   \n2612  65043_60      6.0      6.0     16.0      1.0           60   \n2613  65043_72      3.0      9.0     14.0      1.0           72   \n2614  65043_84      7.0      9.0     20.0      3.0           84   \n\n      on_medication   O00391    O00533   O00584  ...  YSLTYIYTGLSK  YTTEIIK  \\\n0                 0  11254.3  732430.0  39585.8  ...      201158.0  16492.3   \n1                 0      NaN       NaN      NaN  ...           NaN      NaN   \n2                 0  13163.6  630465.0  35220.8  ...      171079.0  13198.8   \n3                 1      NaN       NaN      NaN  ...           NaN      NaN   \n4                 1  15257.6  815083.0  41650.9  ...      231772.0  17873.8   \n...             ...      ...       ...      ...  ...           ...      ...   \n2610              0  10589.6  902434.0  44890.8  ...      233567.0  14478.3   \n2611              0      NaN       NaN      NaN  ...           NaN      NaN   \n2612              0      NaN       NaN      NaN  ...           NaN      NaN   \n2613              0      NaN       NaN      NaN  ...           NaN      NaN   \n2614              0      NaN       NaN      NaN  ...           NaN      NaN   \n\n      YVGGQEHFAHLLILR  YVM(UniMod_35)LPVADQDQC(UniMod_4)IR  \\\n0           3810270.0                             106894.0   \n1                 NaN                                  NaN   \n2           4119520.0                             113385.0   \n3                 NaN                                  NaN   \n4           5474140.0                             116286.0   \n...               ...                                  ...   \n2610        3185530.0                              48793.0   \n2611              NaN                                  NaN   \n2612              NaN                                  NaN   \n2613              NaN                                  NaN   \n2614              NaN                                  NaN   \n\n      YVMLPVADQDQC(UniMod_4)IR  YVNKEIQNAVNGVK  YWGVASFLQK  \\\n0                     580667.0        131155.0    165851.0   \n1                          NaN             NaN         NaN   \n2                     514861.0        103512.0    144607.0   \n3                          NaN             NaN         NaN   \n4                     711815.0        136943.0    181763.0   \n...                        ...             ...         ...   \n2610                  501159.0        133992.0    170146.0   \n2611                       NaN             NaN         NaN   \n2612                       NaN             NaN         NaN   \n2613                       NaN             NaN         NaN   \n2614                       NaN             NaN         NaN   \n\n      YYC(UniMod_4)FQGNQFLR  YYTYLIMNK  YYWGGQYTWDMAK  \n0                  437305.0    46289.2        14898.4  \n1                       NaN        NaN            NaN  \n2                  457891.0    40047.7        20703.9  \n3                       NaN        NaN            NaN  \n4                  452253.0    54725.1        21841.1  \n...                     ...        ...            ...  \n2610               359045.0    45780.0        17370.6  \n2611                    NaN        NaN            NaN  \n2612                    NaN        NaN            NaN  \n2613                    NaN        NaN            NaN  \n2614                    NaN        NaN            NaN  \n\n[2615 rows x 1202 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>visit_id</th>\n      <th>updrs_1</th>\n      <th>updrs_2</th>\n      <th>updrs_3</th>\n      <th>updrs_4</th>\n      <th>visit_month</th>\n      <th>on_medication</th>\n      <th>O00391</th>\n      <th>O00533</th>\n      <th>O00584</th>\n      <th>...</th>\n      <th>YSLTYIYTGLSK</th>\n      <th>YTTEIIK</th>\n      <th>YVGGQEHFAHLLILR</th>\n      <th>YVM(UniMod_35)LPVADQDQC(UniMod_4)IR</th>\n      <th>YVMLPVADQDQC(UniMod_4)IR</th>\n      <th>YVNKEIQNAVNGVK</th>\n      <th>YWGVASFLQK</th>\n      <th>YYC(UniMod_4)FQGNQFLR</th>\n      <th>YYTYLIMNK</th>\n      <th>YYWGGQYTWDMAK</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>55_0</td>\n      <td>10.0</td>\n      <td>6.0</td>\n      <td>15.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11254.3</td>\n      <td>732430.0</td>\n      <td>39585.8</td>\n      <td>...</td>\n      <td>201158.0</td>\n      <td>16492.3</td>\n      <td>3810270.0</td>\n      <td>106894.0</td>\n      <td>580667.0</td>\n      <td>131155.0</td>\n      <td>165851.0</td>\n      <td>437305.0</td>\n      <td>46289.2</td>\n      <td>14898.4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>55_3</td>\n      <td>10.0</td>\n      <td>7.0</td>\n      <td>25.0</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>55_6</td>\n      <td>8.0</td>\n      <td>10.0</td>\n      <td>34.0</td>\n      <td>NaN</td>\n      <td>6</td>\n      <td>0</td>\n      <td>13163.6</td>\n      <td>630465.0</td>\n      <td>35220.8</td>\n      <td>...</td>\n      <td>171079.0</td>\n      <td>13198.8</td>\n      <td>4119520.0</td>\n      <td>113385.0</td>\n      <td>514861.0</td>\n      <td>103512.0</td>\n      <td>144607.0</td>\n      <td>457891.0</td>\n      <td>40047.7</td>\n      <td>20703.9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>55_9</td>\n      <td>8.0</td>\n      <td>9.0</td>\n      <td>30.0</td>\n      <td>0.0</td>\n      <td>9</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>55_12</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>41.0</td>\n      <td>0.0</td>\n      <td>12</td>\n      <td>1</td>\n      <td>15257.6</td>\n      <td>815083.0</td>\n      <td>41650.9</td>\n      <td>...</td>\n      <td>231772.0</td>\n      <td>17873.8</td>\n      <td>5474140.0</td>\n      <td>116286.0</td>\n      <td>711815.0</td>\n      <td>136943.0</td>\n      <td>181763.0</td>\n      <td>452253.0</td>\n      <td>54725.1</td>\n      <td>21841.1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2610</th>\n      <td>65043_48</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>13.0</td>\n      <td>0.0</td>\n      <td>48</td>\n      <td>0</td>\n      <td>10589.6</td>\n      <td>902434.0</td>\n      <td>44890.8</td>\n      <td>...</td>\n      <td>233567.0</td>\n      <td>14478.3</td>\n      <td>3185530.0</td>\n      <td>48793.0</td>\n      <td>501159.0</td>\n      <td>133992.0</td>\n      <td>170146.0</td>\n      <td>359045.0</td>\n      <td>45780.0</td>\n      <td>17370.6</td>\n    </tr>\n    <tr>\n      <th>2611</th>\n      <td>65043_54</td>\n      <td>4.0</td>\n      <td>8.0</td>\n      <td>11.0</td>\n      <td>1.0</td>\n      <td>54</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2612</th>\n      <td>65043_60</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>16.0</td>\n      <td>1.0</td>\n      <td>60</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2613</th>\n      <td>65043_72</td>\n      <td>3.0</td>\n      <td>9.0</td>\n      <td>14.0</td>\n      <td>1.0</td>\n      <td>72</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2614</th>\n      <td>65043_84</td>\n      <td>7.0</td>\n      <td>9.0</td>\n      <td>20.0</td>\n      <td>3.0</td>\n      <td>84</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>2615 rows × 1202 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def smape(A, F):\n    return 100/len(A) * np.sum(2 * np.abs(F - A) / (np.abs(A) + np.abs(F)))","metadata":{"execution":{"iopub.status.busy":"2023-05-15T17:36:50.830671Z","iopub.execute_input":"2023-05-15T17:36:50.830987Z","iopub.status.idle":"2023-05-15T17:36:50.836090Z","shell.execute_reply.started":"2023-05-15T17:36:50.830959Z","shell.execute_reply":"2023-05-15T17:36:50.835092Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport lightgbm as lgb\nfrom sklearn.preprocessing import MinMaxScaler","metadata":{"execution":{"iopub.status.busy":"2023-05-15T17:36:50.837142Z","iopub.execute_input":"2023-05-15T17:36:50.837413Z","iopub.status.idle":"2023-05-15T17:36:52.931754Z","shell.execute_reply.started":"2023-05-15T17:36:50.837390Z","shell.execute_reply":"2023-05-15T17:36:52.931117Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def feature_engineering(dataset):\n    \n    df = dataset.copy()\n    \n    df.dropna(thresh = 610, inplace = True)   # min about half of proteines or peptides\n    \n    features = df.columns[5:]            # leave nulls in updrs for now\n    for feat in features:\n        \n        df[feat].fillna(0, inplace = True)\n        \n        scaler = MinMaxScaler()\n        df[feat] = scaler.fit_transform(df[[feat]])\n        \n    return df","metadata":{"execution":{"iopub.status.busy":"2023-05-15T17:36:52.932754Z","iopub.execute_input":"2023-05-15T17:36:52.933421Z","iopub.status.idle":"2023-05-15T17:36:52.938665Z","shell.execute_reply.started":"2023-05-15T17:36:52.933394Z","shell.execute_reply":"2023-05-15T17:36:52.938013Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### first difference: features were normalized","metadata":{}},{"cell_type":"code","source":"df_eng = feature_engineering(df)\ndf_eng","metadata":{"execution":{"iopub.status.busy":"2023-05-15T17:36:52.941759Z","iopub.execute_input":"2023-05-15T17:36:52.942415Z","iopub.status.idle":"2023-05-15T17:36:59.533390Z","shell.execute_reply.started":"2023-05-15T17:36:52.942393Z","shell.execute_reply":"2023-05-15T17:36:59.532271Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"      visit_id  updrs_1  updrs_2  updrs_3  updrs_4  visit_month  \\\n0         55_0     10.0      6.0     15.0      NaN     0.000000   \n2         55_6      8.0     10.0     34.0      NaN     0.055556   \n4        55_12     10.0     10.0     41.0      0.0     0.111111   \n8        55_36     17.0     18.0     51.0      0.0     0.333333   \n15       942_6      8.0      2.0     21.0      NaN     0.055556   \n...        ...      ...      ...      ...      ...          ...   \n2598  64674_84     11.0     15.0     45.0      4.0     0.777778   \n2600   65043_0      2.0      6.0     16.0      NaN     0.000000   \n2604  65043_12      4.0      7.0     14.0      0.0     0.111111   \n2606  65043_24      4.0      8.0      NaN      0.0     0.222222   \n2610  65043_48      7.0      6.0     13.0      0.0     0.444444   \n\n      on_medication    O00391    O00533    O00584  ...  YSLTYIYTGLSK  \\\n0               0.0  0.526842  0.385009  0.597500  ...      0.490702   \n2               0.0  0.616221  0.326652  0.531615  ...      0.417328   \n4               1.0  0.714247  0.432313  0.628670  ...      0.565382   \n8               1.0  0.633411  0.397258  0.649771  ...      0.451994   \n15              0.0  0.525176  0.194476  0.310645  ...      0.552068   \n...             ...       ...       ...       ...  ...           ...   \n2598            0.0  0.000000  0.074842  0.375955  ...      0.496471   \n2600            0.0  0.630677  0.496912  0.643924  ...      0.627803   \n2604            0.0  0.661690  0.529361  0.437581  ...      0.562125   \n2606            0.0  0.686248  0.573641  0.700962  ...      0.612842   \n2610            0.0  0.495726  0.482307  0.677572  ...      0.569760   \n\n       YTTEIIK  YVGGQEHFAHLLILR  YVM(UniMod_35)LPVADQDQC(UniMod_4)IR  \\\n0     0.596025         0.275001                             0.149952   \n2     0.476999         0.297320                             0.159057   \n4     0.645951         0.395088                             0.163127   \n8     0.671491         0.191957                             0.127567   \n15    0.231286         0.000000                             0.080762   \n...        ...              ...                                  ...   \n2598  0.138616         0.353738                             0.056569   \n2600  0.661954         0.181492                             0.072167   \n2604  0.603646         0.179103                             0.062292   \n2606  0.662301         0.212151                             0.070966   \n2610  0.523240         0.229911                             0.068447   \n\n      YVMLPVADQDQC(UniMod_4)IR  YVNKEIQNAVNGVK  YWGVASFLQK  \\\n0                     0.145724        0.521437    0.627691   \n2                     0.129209        0.411536    0.547289   \n4                     0.178637        0.544449    0.687913   \n8                     0.170442        0.511251    0.770861   \n15                    0.120699        0.318063    0.301494   \n...                        ...             ...         ...   \n2598                  0.084228        0.195806    0.242507   \n2600                  0.133070        0.620803    0.596267   \n2604                  0.136369        0.635433    0.610115   \n2606                  0.150041        0.588536    0.729900   \n2610                  0.125771        0.532716    0.643946   \n\n      YYC(UniMod_4)FQGNQFLR  YYTYLIMNK  YYWGGQYTWDMAK  \n0                  0.461090   0.431722       0.212771  \n2                  0.482796   0.373510       0.295682  \n4                  0.476851   0.510400       0.311923  \n8                  0.525741   0.492377       0.199565  \n15                 0.604482   0.447732       0.223849  \n...                     ...        ...            ...  \n2598               0.704325   0.358818       0.313465  \n2600               0.354934   0.451625       0.155894  \n2604               0.348304   0.423131       0.271679  \n2606               0.409235   0.607172       0.296913  \n2610               0.378573   0.426973       0.248078  \n\n[1067 rows x 1202 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>visit_id</th>\n      <th>updrs_1</th>\n      <th>updrs_2</th>\n      <th>updrs_3</th>\n      <th>updrs_4</th>\n      <th>visit_month</th>\n      <th>on_medication</th>\n      <th>O00391</th>\n      <th>O00533</th>\n      <th>O00584</th>\n      <th>...</th>\n      <th>YSLTYIYTGLSK</th>\n      <th>YTTEIIK</th>\n      <th>YVGGQEHFAHLLILR</th>\n      <th>YVM(UniMod_35)LPVADQDQC(UniMod_4)IR</th>\n      <th>YVMLPVADQDQC(UniMod_4)IR</th>\n      <th>YVNKEIQNAVNGVK</th>\n      <th>YWGVASFLQK</th>\n      <th>YYC(UniMod_4)FQGNQFLR</th>\n      <th>YYTYLIMNK</th>\n      <th>YYWGGQYTWDMAK</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>55_0</td>\n      <td>10.0</td>\n      <td>6.0</td>\n      <td>15.0</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.526842</td>\n      <td>0.385009</td>\n      <td>0.597500</td>\n      <td>...</td>\n      <td>0.490702</td>\n      <td>0.596025</td>\n      <td>0.275001</td>\n      <td>0.149952</td>\n      <td>0.145724</td>\n      <td>0.521437</td>\n      <td>0.627691</td>\n      <td>0.461090</td>\n      <td>0.431722</td>\n      <td>0.212771</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>55_6</td>\n      <td>8.0</td>\n      <td>10.0</td>\n      <td>34.0</td>\n      <td>NaN</td>\n      <td>0.055556</td>\n      <td>0.0</td>\n      <td>0.616221</td>\n      <td>0.326652</td>\n      <td>0.531615</td>\n      <td>...</td>\n      <td>0.417328</td>\n      <td>0.476999</td>\n      <td>0.297320</td>\n      <td>0.159057</td>\n      <td>0.129209</td>\n      <td>0.411536</td>\n      <td>0.547289</td>\n      <td>0.482796</td>\n      <td>0.373510</td>\n      <td>0.295682</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>55_12</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>41.0</td>\n      <td>0.0</td>\n      <td>0.111111</td>\n      <td>1.0</td>\n      <td>0.714247</td>\n      <td>0.432313</td>\n      <td>0.628670</td>\n      <td>...</td>\n      <td>0.565382</td>\n      <td>0.645951</td>\n      <td>0.395088</td>\n      <td>0.163127</td>\n      <td>0.178637</td>\n      <td>0.544449</td>\n      <td>0.687913</td>\n      <td>0.476851</td>\n      <td>0.510400</td>\n      <td>0.311923</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>55_36</td>\n      <td>17.0</td>\n      <td>18.0</td>\n      <td>51.0</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>1.0</td>\n      <td>0.633411</td>\n      <td>0.397258</td>\n      <td>0.649771</td>\n      <td>...</td>\n      <td>0.451994</td>\n      <td>0.671491</td>\n      <td>0.191957</td>\n      <td>0.127567</td>\n      <td>0.170442</td>\n      <td>0.511251</td>\n      <td>0.770861</td>\n      <td>0.525741</td>\n      <td>0.492377</td>\n      <td>0.199565</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>942_6</td>\n      <td>8.0</td>\n      <td>2.0</td>\n      <td>21.0</td>\n      <td>NaN</td>\n      <td>0.055556</td>\n      <td>0.0</td>\n      <td>0.525176</td>\n      <td>0.194476</td>\n      <td>0.310645</td>\n      <td>...</td>\n      <td>0.552068</td>\n      <td>0.231286</td>\n      <td>0.000000</td>\n      <td>0.080762</td>\n      <td>0.120699</td>\n      <td>0.318063</td>\n      <td>0.301494</td>\n      <td>0.604482</td>\n      <td>0.447732</td>\n      <td>0.223849</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2598</th>\n      <td>64674_84</td>\n      <td>11.0</td>\n      <td>15.0</td>\n      <td>45.0</td>\n      <td>4.0</td>\n      <td>0.777778</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.074842</td>\n      <td>0.375955</td>\n      <td>...</td>\n      <td>0.496471</td>\n      <td>0.138616</td>\n      <td>0.353738</td>\n      <td>0.056569</td>\n      <td>0.084228</td>\n      <td>0.195806</td>\n      <td>0.242507</td>\n      <td>0.704325</td>\n      <td>0.358818</td>\n      <td>0.313465</td>\n    </tr>\n    <tr>\n      <th>2600</th>\n      <td>65043_0</td>\n      <td>2.0</td>\n      <td>6.0</td>\n      <td>16.0</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.630677</td>\n      <td>0.496912</td>\n      <td>0.643924</td>\n      <td>...</td>\n      <td>0.627803</td>\n      <td>0.661954</td>\n      <td>0.181492</td>\n      <td>0.072167</td>\n      <td>0.133070</td>\n      <td>0.620803</td>\n      <td>0.596267</td>\n      <td>0.354934</td>\n      <td>0.451625</td>\n      <td>0.155894</td>\n    </tr>\n    <tr>\n      <th>2604</th>\n      <td>65043_12</td>\n      <td>4.0</td>\n      <td>7.0</td>\n      <td>14.0</td>\n      <td>0.0</td>\n      <td>0.111111</td>\n      <td>0.0</td>\n      <td>0.661690</td>\n      <td>0.529361</td>\n      <td>0.437581</td>\n      <td>...</td>\n      <td>0.562125</td>\n      <td>0.603646</td>\n      <td>0.179103</td>\n      <td>0.062292</td>\n      <td>0.136369</td>\n      <td>0.635433</td>\n      <td>0.610115</td>\n      <td>0.348304</td>\n      <td>0.423131</td>\n      <td>0.271679</td>\n    </tr>\n    <tr>\n      <th>2606</th>\n      <td>65043_24</td>\n      <td>4.0</td>\n      <td>8.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.222222</td>\n      <td>0.0</td>\n      <td>0.686248</td>\n      <td>0.573641</td>\n      <td>0.700962</td>\n      <td>...</td>\n      <td>0.612842</td>\n      <td>0.662301</td>\n      <td>0.212151</td>\n      <td>0.070966</td>\n      <td>0.150041</td>\n      <td>0.588536</td>\n      <td>0.729900</td>\n      <td>0.409235</td>\n      <td>0.607172</td>\n      <td>0.296913</td>\n    </tr>\n    <tr>\n      <th>2610</th>\n      <td>65043_48</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>13.0</td>\n      <td>0.0</td>\n      <td>0.444444</td>\n      <td>0.0</td>\n      <td>0.495726</td>\n      <td>0.482307</td>\n      <td>0.677572</td>\n      <td>...</td>\n      <td>0.569760</td>\n      <td>0.523240</td>\n      <td>0.229911</td>\n      <td>0.068447</td>\n      <td>0.125771</td>\n      <td>0.532716</td>\n      <td>0.643946</td>\n      <td>0.378573</td>\n      <td>0.426973</td>\n      <td>0.248078</td>\n    </tr>\n  </tbody>\n</table>\n<p>1067 rows × 1202 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def divide_dataset(df):   # drop nulls of y in divided datasets\n    \n    df1 = df.copy()\n    df1.dropna(subset=['updrs_1'], inplace = True)   \n    df1.drop(columns=['visit_id','updrs_2', 'updrs_3', 'updrs_4'], inplace = True)\n    \n    df2 = df.copy()\n    df2.dropna(subset=['updrs_2'], inplace = True)\n    df2.drop(columns=['visit_id','updrs_1', 'updrs_3', 'updrs_4'], inplace = True)\n    \n    df3 = df.copy()\n    df3.dropna(subset=['updrs_3'], inplace = True)\n    df3.drop(columns=['visit_id','updrs_1', 'updrs_2', 'updrs_4'], inplace = True)\n    \n    df4 = df.copy()\n    df4.dropna(subset=['updrs_4'], inplace = True)\n    df4.drop(columns=['visit_id','updrs_1', 'updrs_2', 'updrs_3'], inplace = True)\n    \n    return df1, df2, df3, df4","metadata":{"execution":{"iopub.status.busy":"2023-05-15T17:36:59.534546Z","iopub.execute_input":"2023-05-15T17:36:59.534842Z","iopub.status.idle":"2023-05-15T17:36:59.542333Z","shell.execute_reply.started":"2023-05-15T17:36:59.534818Z","shell.execute_reply":"2023-05-15T17:36:59.541106Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Training and prediction","metadata":{}},{"cell_type":"code","source":"def get_training_subset(df):\n    \n    X = df.iloc[:, 1:]\n    y = df.iloc[:, 0]\n    \n    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state=42)\n    \n    return X_train, X_val, y_train, y_val","metadata":{"execution":{"iopub.status.busy":"2023-05-15T17:36:59.543312Z","iopub.execute_input":"2023-05-15T17:36:59.543614Z","iopub.status.idle":"2023-05-15T17:36:59.556937Z","shell.execute_reply.started":"2023-05-15T17:36:59.543590Z","shell.execute_reply":"2023-05-15T17:36:59.556095Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def get_training_subsets(df1, df2, df3, df4):\n        \n    dataset = []\n    \n    data = get_training_subset(df1)\n    dataset.append((data))\n    \n    data = get_training_subset(df2)\n    dataset.append((data))\n    \n    data = get_training_subset(df3)\n    dataset.append((data))\n    \n    data = get_training_subset(df4)\n    dataset.append((data))\n\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2023-05-15T17:36:59.558253Z","iopub.execute_input":"2023-05-15T17:36:59.558517Z","iopub.status.idle":"2023-05-15T17:36:59.568078Z","shell.execute_reply.started":"2023-05-15T17:36:59.558496Z","shell.execute_reply":"2023-05-15T17:36:59.567291Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def predict_label(Xt, Xv, yt, yv):\n    lgbm_model = lgb.LGBMRegressor(metric = 'mse', early_stopping_round = 10, random_state = 42, verbose= -100)    \n    lgbm_model.fit(Xt, yt, eval_set = (Xv, yv), verbose= False)\n    yp = lgbm_model.predict(Xv)\n    smape_score = smape(yv, yp)\n    return smape_score","metadata":{"execution":{"iopub.status.busy":"2023-05-15T17:36:59.569005Z","iopub.execute_input":"2023-05-15T17:36:59.569287Z","iopub.status.idle":"2023-05-15T17:36:59.578291Z","shell.execute_reply.started":"2023-05-15T17:36:59.569268Z","shell.execute_reply":"2023-05-15T17:36:59.577436Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def predict_labels(data):\n    \n    X1_train, X1_val, y1_train, y1_val = data[0]\n    X2_train, X2_val, y2_train, y2_val = data[1]\n    X3_train, X3_val, y3_train, y3_val = data[2]\n    X4_train, X4_val, y4_train, y4_val = data[3]\n    \n    smape_score = []\n    \n    print(\"\\nPREDICTION OF LABELS\")\n    print(\"=======================================\")\n    \n    smape = predict_label(X1_train, X1_val, y1_train, y1_val)\n    smape_score.append(smape)\n    \n    smape = predict_label(X2_train, X2_val, y2_train, y2_val)\n    smape_score.append(smape)\n    \n    smape = predict_label(X3_train, X3_val, y3_train, y3_val)\n    smape_score.append(smape)\n    \n    smape = predict_label(X4_train, X4_val, y4_train, y4_val)\n    smape_score.append(smape)\n\n    for ind, smape in enumerate(smape_score):\n        print(f\"sMAPE for label {ind}: {smape}\")\n    \n    y_lengths = np.array([len(data[0][2]), len(data[1][2]), len(data[2][2]), len(data[3][2])])\n    weights = y_lengths / sum(y_lengths)\n    smape_score_wav = sum(weights * np.array(smape_score))\n    \n    print(f\"\\nsMAPE weighted average of labels: {smape_score_wav:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2023-05-15T17:36:59.579185Z","iopub.execute_input":"2023-05-15T17:36:59.579849Z","iopub.status.idle":"2023-05-15T17:36:59.591262Z","shell.execute_reply.started":"2023-05-15T17:36:59.579826Z","shell.execute_reply":"2023-05-15T17:36:59.590191Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"df1, df2, df3, df4 = divide_dataset(df_eng)         # separate datasets for labels with features\nsubsets = get_training_subsets(df1, df2, df3, df4)  # train and validation for each label\npredict_labels(subsets)                             # result of feature engineering","metadata":{"execution":{"iopub.status.busy":"2023-05-15T17:36:59.592192Z","iopub.execute_input":"2023-05-15T17:36:59.592415Z","iopub.status.idle":"2023-05-15T17:37:09.539846Z","shell.execute_reply.started":"2023-05-15T17:36:59.592396Z","shell.execute_reply":"2023-05-15T17:37:09.538948Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"\nPREDICTION OF LABELS\n=======================================\nsMAPE for label 0: 60.92453954800605\nsMAPE for label 1: 96.86446697209053\nsMAPE for label 2: 83.48040705329346\nsMAPE for label 3: 149.0455723512696\n\nsMAPE weighted average of labels: 90.7826\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### note: sMAPE a little bit worse than without normalization (90.78 vs 90.52)","metadata":{}},{"cell_type":"markdown","source":"# Reduction of dimensions","metadata":{}},{"cell_type":"code","source":"from sklearn.manifold import LocallyLinearEmbedding","metadata":{"execution":{"iopub.status.busy":"2023-05-15T17:37:09.541878Z","iopub.execute_input":"2023-05-15T17:37:09.542288Z","iopub.status.idle":"2023-05-15T17:37:09.809327Z","shell.execute_reply.started":"2023-05-15T17:37:09.542253Z","shell.execute_reply":"2023-05-15T17:37:09.808423Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def reduce_features(dataset, components):\n    labels = dataset.iloc[:,:5].reset_index(drop=True)\n    features = dataset.iloc[:,5:].reset_index(drop=True)\n    \n    embedding = LocallyLinearEmbedding(n_components=components)\n    red_features = embedding.fit_transform(features)\n    X_features = pd.DataFrame(red_features, columns=['feature_'+str(f+1) for f in range(components)])\n    \n    df = pd.concat([labels,X_features], axis=1)\n    return df","metadata":{"execution":{"iopub.status.busy":"2023-05-15T17:37:09.810506Z","iopub.execute_input":"2023-05-15T17:37:09.810825Z","iopub.status.idle":"2023-05-15T17:37:09.820313Z","shell.execute_reply.started":"2023-05-15T17:37:09.810798Z","shell.execute_reply":"2023-05-15T17:37:09.819182Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"### this time it bases on sklearn model, not on order of correlations","metadata":{}},{"cell_type":"code","source":"df_red = reduce_features(df_eng, 200)\ndf_red","metadata":{"execution":{"iopub.status.busy":"2023-05-15T17:37:09.821264Z","iopub.execute_input":"2023-05-15T17:37:09.821514Z","iopub.status.idle":"2023-05-15T17:37:10.271200Z","shell.execute_reply.started":"2023-05-15T17:37:09.821494Z","shell.execute_reply":"2023-05-15T17:37:10.270431Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"      visit_id  updrs_1  updrs_2  updrs_3  updrs_4  feature_1  feature_2  \\\n0         55_0     10.0      6.0     15.0      NaN  -0.029483   0.007609   \n1         55_6      8.0     10.0     34.0      NaN  -0.029423   0.008061   \n2        55_12     10.0     10.0     41.0      0.0  -0.029492   0.007535   \n3        55_36     17.0     18.0     51.0      0.0  -0.029467   0.007738   \n4        942_6      8.0      2.0     21.0      NaN  -0.029298   0.008994   \n...        ...      ...      ...      ...      ...        ...        ...   \n1062  64674_84     11.0     15.0     45.0      4.0  -0.029298   0.008995   \n1063   65043_0      2.0      6.0     16.0      NaN  -0.029282   0.006466   \n1064  65043_12      4.0      7.0     14.0      0.0  -0.029638   0.006221   \n1065  65043_24      4.0      8.0      NaN      0.0  -0.030090   0.003989   \n1066  65043_48      7.0      6.0     13.0      0.0  -0.029598   0.006882   \n\n      feature_3  feature_4  feature_5  ...  feature_191  feature_192  \\\n0     -0.005253  -0.036143   0.021358  ...    -0.006273    -0.014014   \n1     -0.005163  -0.037161   0.023864  ...    -0.003533    -0.001917   \n2     -0.005271  -0.035975   0.020797  ...    -0.004869    -0.013856   \n3     -0.005226  -0.036462   0.020147  ...    -0.006478    -0.016727   \n4     -0.004982  -0.010041  -0.013215  ...    -0.025436    -0.024216   \n...         ...        ...        ...  ...          ...          ...   \n1062  -0.004982   0.064592   0.011071  ...    -0.015384    -0.047683   \n1063  -0.006706  -0.032185   0.009685  ...     0.015835     0.023505   \n1064  -0.005633  -0.032786   0.015199  ...     0.029906     0.038240   \n1065  -0.005537  -0.032729   0.014524  ...     0.027700     0.035792   \n1066  -0.005334  -0.034367   0.015903  ...     0.006898     0.025639   \n\n      feature_193  feature_194  feature_195  feature_196  feature_197  \\\n0        0.013008     0.014814     0.001044    -0.004016    -0.005724   \n1        0.009694     0.000641    -0.011341     0.002867     0.005759   \n2        0.010170     0.015864     0.004366    -0.005416    -0.007294   \n3        0.016060     0.019224     0.004332    -0.005924    -0.010024   \n4       -0.014347    -0.009203    -0.018215     0.025046    -0.009078   \n...           ...          ...          ...          ...          ...   \n1062    -0.030049    -0.012209    -0.010666     0.085271    -0.008025   \n1063    -0.013964    -0.011779     0.008268     0.010167     0.026834   \n1064    -0.069229    -0.034061     0.007724     0.009131     0.026117   \n1065    -0.066375    -0.034907     0.004785     0.007392     0.022921   \n1066    -0.046993    -0.019806     0.004083     0.001406     0.014838   \n\n      feature_198  feature_199  feature_200  \n0        0.000227    -0.000623    -0.008016  \n1       -0.006772     0.015998     0.018127  \n2        0.003828    -0.006994    -0.013018  \n3        0.003234    -0.006795    -0.015854  \n4        0.006711    -0.005357    -0.005679  \n...           ...          ...          ...  \n1062     0.035007     0.026386     0.016849  \n1063     0.004998     0.009954     0.013929  \n1064     0.012401    -0.018738     0.012964  \n1065     0.012363    -0.020963     0.015626  \n1066     0.008468    -0.000908     0.013257  \n\n[1067 rows x 205 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>visit_id</th>\n      <th>updrs_1</th>\n      <th>updrs_2</th>\n      <th>updrs_3</th>\n      <th>updrs_4</th>\n      <th>feature_1</th>\n      <th>feature_2</th>\n      <th>feature_3</th>\n      <th>feature_4</th>\n      <th>feature_5</th>\n      <th>...</th>\n      <th>feature_191</th>\n      <th>feature_192</th>\n      <th>feature_193</th>\n      <th>feature_194</th>\n      <th>feature_195</th>\n      <th>feature_196</th>\n      <th>feature_197</th>\n      <th>feature_198</th>\n      <th>feature_199</th>\n      <th>feature_200</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>55_0</td>\n      <td>10.0</td>\n      <td>6.0</td>\n      <td>15.0</td>\n      <td>NaN</td>\n      <td>-0.029483</td>\n      <td>0.007609</td>\n      <td>-0.005253</td>\n      <td>-0.036143</td>\n      <td>0.021358</td>\n      <td>...</td>\n      <td>-0.006273</td>\n      <td>-0.014014</td>\n      <td>0.013008</td>\n      <td>0.014814</td>\n      <td>0.001044</td>\n      <td>-0.004016</td>\n      <td>-0.005724</td>\n      <td>0.000227</td>\n      <td>-0.000623</td>\n      <td>-0.008016</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>55_6</td>\n      <td>8.0</td>\n      <td>10.0</td>\n      <td>34.0</td>\n      <td>NaN</td>\n      <td>-0.029423</td>\n      <td>0.008061</td>\n      <td>-0.005163</td>\n      <td>-0.037161</td>\n      <td>0.023864</td>\n      <td>...</td>\n      <td>-0.003533</td>\n      <td>-0.001917</td>\n      <td>0.009694</td>\n      <td>0.000641</td>\n      <td>-0.011341</td>\n      <td>0.002867</td>\n      <td>0.005759</td>\n      <td>-0.006772</td>\n      <td>0.015998</td>\n      <td>0.018127</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>55_12</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>41.0</td>\n      <td>0.0</td>\n      <td>-0.029492</td>\n      <td>0.007535</td>\n      <td>-0.005271</td>\n      <td>-0.035975</td>\n      <td>0.020797</td>\n      <td>...</td>\n      <td>-0.004869</td>\n      <td>-0.013856</td>\n      <td>0.010170</td>\n      <td>0.015864</td>\n      <td>0.004366</td>\n      <td>-0.005416</td>\n      <td>-0.007294</td>\n      <td>0.003828</td>\n      <td>-0.006994</td>\n      <td>-0.013018</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>55_36</td>\n      <td>17.0</td>\n      <td>18.0</td>\n      <td>51.0</td>\n      <td>0.0</td>\n      <td>-0.029467</td>\n      <td>0.007738</td>\n      <td>-0.005226</td>\n      <td>-0.036462</td>\n      <td>0.020147</td>\n      <td>...</td>\n      <td>-0.006478</td>\n      <td>-0.016727</td>\n      <td>0.016060</td>\n      <td>0.019224</td>\n      <td>0.004332</td>\n      <td>-0.005924</td>\n      <td>-0.010024</td>\n      <td>0.003234</td>\n      <td>-0.006795</td>\n      <td>-0.015854</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>942_6</td>\n      <td>8.0</td>\n      <td>2.0</td>\n      <td>21.0</td>\n      <td>NaN</td>\n      <td>-0.029298</td>\n      <td>0.008994</td>\n      <td>-0.004982</td>\n      <td>-0.010041</td>\n      <td>-0.013215</td>\n      <td>...</td>\n      <td>-0.025436</td>\n      <td>-0.024216</td>\n      <td>-0.014347</td>\n      <td>-0.009203</td>\n      <td>-0.018215</td>\n      <td>0.025046</td>\n      <td>-0.009078</td>\n      <td>0.006711</td>\n      <td>-0.005357</td>\n      <td>-0.005679</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1062</th>\n      <td>64674_84</td>\n      <td>11.0</td>\n      <td>15.0</td>\n      <td>45.0</td>\n      <td>4.0</td>\n      <td>-0.029298</td>\n      <td>0.008995</td>\n      <td>-0.004982</td>\n      <td>0.064592</td>\n      <td>0.011071</td>\n      <td>...</td>\n      <td>-0.015384</td>\n      <td>-0.047683</td>\n      <td>-0.030049</td>\n      <td>-0.012209</td>\n      <td>-0.010666</td>\n      <td>0.085271</td>\n      <td>-0.008025</td>\n      <td>0.035007</td>\n      <td>0.026386</td>\n      <td>0.016849</td>\n    </tr>\n    <tr>\n      <th>1063</th>\n      <td>65043_0</td>\n      <td>2.0</td>\n      <td>6.0</td>\n      <td>16.0</td>\n      <td>NaN</td>\n      <td>-0.029282</td>\n      <td>0.006466</td>\n      <td>-0.006706</td>\n      <td>-0.032185</td>\n      <td>0.009685</td>\n      <td>...</td>\n      <td>0.015835</td>\n      <td>0.023505</td>\n      <td>-0.013964</td>\n      <td>-0.011779</td>\n      <td>0.008268</td>\n      <td>0.010167</td>\n      <td>0.026834</td>\n      <td>0.004998</td>\n      <td>0.009954</td>\n      <td>0.013929</td>\n    </tr>\n    <tr>\n      <th>1064</th>\n      <td>65043_12</td>\n      <td>4.0</td>\n      <td>7.0</td>\n      <td>14.0</td>\n      <td>0.0</td>\n      <td>-0.029638</td>\n      <td>0.006221</td>\n      <td>-0.005633</td>\n      <td>-0.032786</td>\n      <td>0.015199</td>\n      <td>...</td>\n      <td>0.029906</td>\n      <td>0.038240</td>\n      <td>-0.069229</td>\n      <td>-0.034061</td>\n      <td>0.007724</td>\n      <td>0.009131</td>\n      <td>0.026117</td>\n      <td>0.012401</td>\n      <td>-0.018738</td>\n      <td>0.012964</td>\n    </tr>\n    <tr>\n      <th>1065</th>\n      <td>65043_24</td>\n      <td>4.0</td>\n      <td>8.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>-0.030090</td>\n      <td>0.003989</td>\n      <td>-0.005537</td>\n      <td>-0.032729</td>\n      <td>0.014524</td>\n      <td>...</td>\n      <td>0.027700</td>\n      <td>0.035792</td>\n      <td>-0.066375</td>\n      <td>-0.034907</td>\n      <td>0.004785</td>\n      <td>0.007392</td>\n      <td>0.022921</td>\n      <td>0.012363</td>\n      <td>-0.020963</td>\n      <td>0.015626</td>\n    </tr>\n    <tr>\n      <th>1066</th>\n      <td>65043_48</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>13.0</td>\n      <td>0.0</td>\n      <td>-0.029598</td>\n      <td>0.006882</td>\n      <td>-0.005334</td>\n      <td>-0.034367</td>\n      <td>0.015903</td>\n      <td>...</td>\n      <td>0.006898</td>\n      <td>0.025639</td>\n      <td>-0.046993</td>\n      <td>-0.019806</td>\n      <td>0.004083</td>\n      <td>0.001406</td>\n      <td>0.014838</td>\n      <td>0.008468</td>\n      <td>-0.000908</td>\n      <td>0.013257</td>\n    </tr>\n  </tbody>\n</table>\n<p>1067 rows × 205 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df1, df2, df3, df4 = divide_dataset(df_red)         # separate datasets for labels with features\nsubsets = get_training_subsets(df1, df2, df3, df4)  # train and validation for each label\npredict_labels(subsets)                             # result of feature engineering","metadata":{"execution":{"iopub.status.busy":"2023-05-15T17:37:10.274079Z","iopub.execute_input":"2023-05-15T17:37:10.275999Z","iopub.status.idle":"2023-05-15T17:37:13.171749Z","shell.execute_reply.started":"2023-05-15T17:37:10.275973Z","shell.execute_reply":"2023-05-15T17:37:13.170723Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"\nPREDICTION OF LABELS\n=======================================\nsMAPE for label 0: 57.526158878297615\nsMAPE for label 1: 93.38772006842035\nsMAPE for label 2: 78.00320495725616\nsMAPE for label 3: 143.52478056834542\n\nsMAPE weighted average of labels: 86.4567\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### with number of components 200 sMAPE improved notticeably (from 90.78 to 86.46)","metadata":{}},{"cell_type":"markdown","source":"# Clustering","metadata":{}},{"cell_type":"code","source":"from sklearn.cluster import KMeans","metadata":{"execution":{"iopub.status.busy":"2023-05-15T17:37:13.173087Z","iopub.execute_input":"2023-05-15T17:37:13.173352Z","iopub.status.idle":"2023-05-15T17:37:13.248280Z","shell.execute_reply.started":"2023-05-15T17:37:13.173330Z","shell.execute_reply":"2023-05-15T17:37:13.247446Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def predict_clustered_label(df, clust_nr, verbose = True):\n    \n    model_clust_km = KMeans(n_clusters = clust_nr, init='k-means++', n_init='auto', random_state=42)\n    y_clust = model_clust_km.fit_predict(df.iloc[:,1:])\n    \n    df_clust = df.copy()\n    df_clust['cluster'] = y_clust   # for validation calculated not predicted yet\n    \n    cl_numbers = y_clust.tolist()\n    clusters = np.unique(cl_numbers)\n    \n    cl_entries = []\n    smape_score = []\n    \n    for cluster in clusters:\n    \n        df_cl = df_clust[df_clust['cluster'] == cluster].drop(columns=['cluster'])\n        \n        if len(df_cl)>=8:\n            X_train, X_val, y_train, y_val = get_training_subset(df_cl)\n            smape = predict_label(X_train, X_val, y_train, y_val)\n        \n            entries = cl_numbers.count(cluster)\n            cl_entries.append(entries)\n            smape_score.append(smape)\n        \n        else:\n            cl_entries.append(0)\n            smape_score.append(0)\n    \n    weights = np.array(cl_entries) / sum(cl_entries)\n    smape_score_wav = sum(weights * np.array(smape_score))\n    \n    if verbose:\n        for ind, cluster in enumerate(clusters):\n            print(f\"CLUSTER {cluster}:sMAPE: {smape_score[ind]:.4f}, entries: {cl_entries[ind]}\")\n    \n    print(f\"sMAPE weighted average in clusters: {smape_score_wav:.4f}, entries: {sum(cl_entries)}\")\n    \n    return smape_score_wav","metadata":{"execution":{"iopub.status.busy":"2023-05-15T17:37:13.249619Z","iopub.execute_input":"2023-05-15T17:37:13.249832Z","iopub.status.idle":"2023-05-15T17:37:13.256591Z","shell.execute_reply.started":"2023-05-15T17:37:13.249812Z","shell.execute_reply":"2023-05-15T17:37:13.256058Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def predict_clustered_labels(df1, df2, df3, df4, clust_nr_list):\n    \n    dfs = (df1.copy(), df2.copy(), df3.copy(), df4.copy())\n    smape_score = []\n    \n    print(\"\\nPREDICTION OF CLUSTERED LABELS\")\n    print(\"=================================================\")\n    \n    for ind, df in enumerate(dfs):\n        print(f\"\\nLABEL: {df.columns[0]}\")\n        smape = predict_clustered_label(df, clust_nr_list[ind])\n        smape_score.append(smape)\n        print(\"------------------------------------------------\")\n            \n    y_lengths = np.array([len(dfs[0]), len(dfs[1]), len(dfs[2]), len(dfs[3])])\n    weights = y_lengths / sum(y_lengths)\n    smape_score_wav = sum(weights * np.array(smape_score))\n    \n    print(f\"\\nsMAPE weighted average of labels: {smape_score_wav:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2023-05-15T17:37:13.257379Z","iopub.execute_input":"2023-05-15T17:37:13.257708Z","iopub.status.idle":"2023-05-15T17:37:13.269275Z","shell.execute_reply.started":"2023-05-15T17:37:13.257690Z","shell.execute_reply":"2023-05-15T17:37:13.268214Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"predict_clustered_labels(df1, df2, df3, df4, [3, 3, 3, 3])     # random number of clusters yet","metadata":{"execution":{"iopub.status.busy":"2023-05-15T17:37:13.270458Z","iopub.execute_input":"2023-05-15T17:37:13.270747Z","iopub.status.idle":"2023-05-15T17:37:15.794664Z","shell.execute_reply.started":"2023-05-15T17:37:13.270723Z","shell.execute_reply":"2023-05-15T17:37:15.793806Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"\nPREDICTION OF CLUSTERED LABELS\n=================================================\n\nLABEL: updrs_1\nCLUSTER 0:sMAPE: 0.0000, entries: 0\nCLUSTER 1:sMAPE: 59.8836, entries: 1043\nCLUSTER 2:sMAPE: 120.7051, entries: 21\nsMAPE weighted average in clusters: 61.0841, entries: 1064\n------------------------------------------------\n\nLABEL: updrs_2\nCLUSTER 0:sMAPE: 0.0000, entries: 0\nCLUSTER 1:sMAPE: 86.5001, entries: 1043\nCLUSTER 2:sMAPE: 178.1818, entries: 21\nsMAPE weighted average in clusters: 88.3096, entries: 1064\n------------------------------------------------\n\nLABEL: updrs_3\nCLUSTER 0:sMAPE: 0.0000, entries: 0\nCLUSTER 1:sMAPE: 72.6375, entries: 1045\nCLUSTER 2:sMAPE: 32.1952, entries: 8\nsMAPE weighted average in clusters: 72.3302, entries: 1053\n------------------------------------------------\n\nLABEL: updrs_4\nCLUSTER 0:sMAPE: 144.4871, entries: 555\nCLUSTER 1:sMAPE: 0.0000, entries: 0\nCLUSTER 2:sMAPE: 0.0000, entries: 0\nsMAPE weighted average in clusters: 144.4871, entries: 555\n------------------------------------------------\n\nsMAPE weighted average of labels: 84.5770\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### random number of clusters (3) improved sMAPE a bit (from 86.46 to 84.58)","metadata":{}},{"cell_type":"code","source":"def search_clusters_for_label(dataset, max_clust):\n    \n    df = dataset.copy()\n    min_smape_clus = 0\n    min_smape = 200\n    \n    Xt, Xv, yt, yv = get_training_subset(df)\n    smape_lab = predict_label(Xt, Xv, yt, yv)\n        \n    print(f\"\\nsMAPE before clustering: {smape_lab}\")\n    if smape_lab < min_smape:\n        min_smape = smape_lab\n        min_smape_clus = 1\n        \n    clust_numbers = np.arange(2, max_clust+1)\n    for clust_nr in clust_numbers:\n        print(f\"number of clusters: {clust_nr}\")\n        smape_clust = predict_clustered_label(df, clust_nr, verbose = False)\n                \n        if smape_clust < min_smape:\n            min_smape = smape_clust\n            min_smape_clus = clust_nr\n        \n    return min_smape, min_smape_clus","metadata":{"execution":{"iopub.status.busy":"2023-05-15T17:37:15.795845Z","iopub.execute_input":"2023-05-15T17:37:15.796116Z","iopub.status.idle":"2023-05-15T17:37:15.801682Z","shell.execute_reply.started":"2023-05-15T17:37:15.796095Z","shell.execute_reply":"2023-05-15T17:37:15.800893Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def search_clusters_for_labels(df1, df2, df3, df4, max_clust):\n    \n    label1 = df1.columns[0]\n    label2 = df2.columns[0]\n    label3 = df3.columns[0]\n    label4 = df4.columns[0]\n    \n    print(f\"\\nSearching clusters for label {label1}\")\n    min_smape1, min_smape_clus1 = search_clusters_for_label(df1, max_clust)\n    \n    print(\"---------------------------------------\")\n    print(f\"\\nSearching clusters for label {label2}\")\n    min_smape2, min_smape_clus2 = search_clusters_for_label(df2, max_clust)\n    \n    print(\"---------------------------------------\")\n    print(f\"\\nSearching clusters for label {label3}\")\n    min_smape3, min_smape_clus3 = search_clusters_for_label(df3, max_clust)\n    \n    print(\"---------------------------------------\")\n    print(f\"\\nSearching clusters for label {label4}\")\n    min_smape4, min_smape_clus4 = search_clusters_for_label(df4, max_clust)\n    \n    print(\"\\n\\nSUMMARY\")\n    print(\"==================================================\")\n    print(f\"\\nLABEL {label1}\")\n    print(f\"Min sMAPE: {min_smape1} for clusters number: {min_smape_clus1}\")\n    print(f\"\\nLABEL {label2}\")\n    print(f\"Min sMAPE: {min_smape2} for clusters number: {min_smape_clus2}\")\n    print(f\"\\nLABEL {label3}\")\n    print(f\"Min sMAPE: {min_smape3} for clusters number: {min_smape_clus3}\")\n    print(f\"\\nLABEL {label4}\")\n    print(f\"Min sMAPE: {min_smape4} for clusters number: {min_smape_clus4}\")\n    \n    y_lengths = np.array([len(df1), len(df2), len(df3), len(df4)])\n    weights = y_lengths / sum(y_lengths)\n    smape_score_wav = sum(weights * np.array([min_smape1, min_smape2, min_smape3, min_smape4]))\n    \n    print(f\"\\nsMAPE weighted average of labels: {smape_score_wav:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2023-05-15T17:37:15.802636Z","iopub.execute_input":"2023-05-15T17:37:15.802854Z","iopub.status.idle":"2023-05-15T17:37:15.815088Z","shell.execute_reply.started":"2023-05-15T17:37:15.802834Z","shell.execute_reply":"2023-05-15T17:37:15.814214Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"search_clusters_for_labels(df1, df2, df3, df4, 10)","metadata":{"execution":{"iopub.status.busy":"2023-05-15T17:37:15.816126Z","iopub.execute_input":"2023-05-15T17:37:15.816348Z","iopub.status.idle":"2023-05-15T17:37:43.070469Z","shell.execute_reply.started":"2023-05-15T17:37:15.816328Z","shell.execute_reply":"2023-05-15T17:37:43.069596Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"\nSearching clusters for label updrs_1\n\nsMAPE before clustering: 57.526158878297615\nnumber of clusters: 2\nsMAPE weighted average in clusters: 55.4739, entries: 1064\nnumber of clusters: 3\nsMAPE weighted average in clusters: 61.0841, entries: 1064\nnumber of clusters: 4\nsMAPE weighted average in clusters: 62.1306, entries: 1064\nnumber of clusters: 5\nsMAPE weighted average in clusters: 57.9692, entries: 1064\nnumber of clusters: 6\nsMAPE weighted average in clusters: 56.2567, entries: 1057\nnumber of clusters: 7\nsMAPE weighted average in clusters: 57.6901, entries: 1051\nnumber of clusters: 8\nsMAPE weighted average in clusters: 59.5130, entries: 1058\nnumber of clusters: 9\nsMAPE weighted average in clusters: 65.5340, entries: 1058\nnumber of clusters: 10\nsMAPE weighted average in clusters: 68.4570, entries: 1058\n---------------------------------------\n\nSearching clusters for label updrs_2\n\nsMAPE before clustering: 93.38772006842035\nnumber of clusters: 2\nsMAPE weighted average in clusters: 94.9638, entries: 1064\nnumber of clusters: 3\nsMAPE weighted average in clusters: 88.3096, entries: 1064\nnumber of clusters: 4\nsMAPE weighted average in clusters: 89.0114, entries: 1064\nnumber of clusters: 5\nsMAPE weighted average in clusters: 89.6744, entries: 1064\nnumber of clusters: 6\nsMAPE weighted average in clusters: 87.9052, entries: 1057\nnumber of clusters: 7\nsMAPE weighted average in clusters: 86.8793, entries: 1051\nnumber of clusters: 8\nsMAPE weighted average in clusters: 89.9076, entries: 1058\nnumber of clusters: 9\nsMAPE weighted average in clusters: 97.9812, entries: 1058\nnumber of clusters: 10\nsMAPE weighted average in clusters: 85.9082, entries: 1058\n---------------------------------------\n\nSearching clusters for label updrs_3\n\nsMAPE before clustering: 78.00320495725616\nnumber of clusters: 2\nsMAPE weighted average in clusters: 75.3342, entries: 1053\nnumber of clusters: 3\nsMAPE weighted average in clusters: 72.3302, entries: 1053\nnumber of clusters: 4\nsMAPE weighted average in clusters: 73.5972, entries: 1053\nnumber of clusters: 5\nsMAPE weighted average in clusters: 69.4653, entries: 1047\nnumber of clusters: 6\nsMAPE weighted average in clusters: 73.6186, entries: 1043\nnumber of clusters: 7\nsMAPE weighted average in clusters: 75.3118, entries: 1039\nnumber of clusters: 8\nsMAPE weighted average in clusters: 74.6760, entries: 1038\nnumber of clusters: 9\nsMAPE weighted average in clusters: 66.9845, entries: 1032\nnumber of clusters: 10\nsMAPE weighted average in clusters: 73.0089, entries: 1029\n---------------------------------------\n\nSearching clusters for label updrs_4\n\nsMAPE before clustering: 143.52478056834542\nnumber of clusters: 2\nsMAPE weighted average in clusters: 149.7494, entries: 562\nnumber of clusters: 3\nsMAPE weighted average in clusters: 144.4871, entries: 555\nnumber of clusters: 4\nsMAPE weighted average in clusters: 148.8553, entries: 548\nnumber of clusters: 5\nsMAPE weighted average in clusters: 154.8164, entries: 541\nnumber of clusters: 6\nsMAPE weighted average in clusters: 156.3425, entries: 537\nnumber of clusters: 7\nsMAPE weighted average in clusters: 148.6902, entries: 540\nnumber of clusters: 8\nsMAPE weighted average in clusters: 140.0759, entries: 548\nnumber of clusters: 9\nsMAPE weighted average in clusters: 145.7746, entries: 543\nnumber of clusters: 10\nsMAPE weighted average in clusters: 150.6450, entries: 543\n\n\nSUMMARY\n==================================================\n\nLABEL updrs_1\nMin sMAPE: 55.47393868669026 for clusters number: 2\n\nLABEL updrs_2\nMin sMAPE: 85.90816544661739 for clusters number: 10\n\nLABEL updrs_3\nMin sMAPE: 66.98454603721608 for clusters number: 9\n\nLABEL updrs_4\nMin sMAPE: 140.07589253683517 for clusters number: 8\n\nsMAPE weighted average of labels: 80.1331\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### finding optimal number of clusters for each label (2, 10, 9, 8) caused further improvement of sMAPE (from 84.58 to 80.13)","metadata":{}},{"cell_type":"markdown","source":"# Prediction of assignment to clusters (calulated for training dataset) for validation data","metadata":{}},{"cell_type":"code","source":"def get_cluster_model(Xt, Xv, yt, yv):\n    lgbm_model = lgb.LGBMClassifier(random_state = 42, verbose= -100)    \n    lgbm_model.fit(Xt, yt, eval_set = (Xv, yv), verbose= False)\n    return lgbm_model","metadata":{"execution":{"iopub.status.busy":"2023-05-15T17:37:43.074370Z","iopub.execute_input":"2023-05-15T17:37:43.074634Z","iopub.status.idle":"2023-05-15T17:37:43.079157Z","shell.execute_reply.started":"2023-05-15T17:37:43.074614Z","shell.execute_reply":"2023-05-15T17:37:43.078107Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def predict_clustered_label_2(df, clust_nr, verbose = True):\n    \n    # on the basis of clusters calculated for X_train\n    # we have to predict to which cluster each x_val belongs\n    \n    X_train, X_val, y_train, y_val = get_training_subset(df)\n    \n    model_clust_km = KMeans(n_clusters = clust_nr, init='k-means++', n_init='auto', random_state=42)\n    clust_calc = model_clust_km.fit_predict(X_train)   \n    df_train = X_train.copy()\n    df_train.insert(loc=0, column='cluster', value=clust_calc)   # new label, i.e. cluster nr, should be in first column before getting subsets\n\n    X_train_cl, X_val_cl, y_train_cl, y_val_cl = get_training_subset(df_train)\n    clust_model = get_cluster_model(X_train_cl, X_val_cl, y_train_cl, y_val_cl)\n    clust_pred = clust_model.predict(X_val)\n    df_val = X_val.copy()\n    df_val.insert(loc=0, column='cluster', value=clust_pred)\n    \n    df_train.insert(loc=0, column='y', value = y_train)\n    df_val.insert(loc=0, column='y', value = y_val)\n                  \n    cl_numbers = clust_calc.tolist()\n    clusters = np.unique(cl_numbers)\n    \n    cl_entries = []\n    smape_score = []\n    \n    for cluster in clusters:\n    \n        df_cl_train = df_train[df_train['cluster'] == cluster].drop(columns=['cluster'])\n        df_cl_val = df_val[df_val['cluster'] == cluster].drop(columns=['cluster'])\n        \n        if len(df_cl_val)>=2:\n            smape = predict_label(df_cl_train.iloc[:,1:], df_cl_val.iloc[:,1:], df_cl_train.iloc[:,0], df_cl_val.iloc[:,0])\n        \n            entries = cl_numbers.count(cluster)\n            cl_entries.append(entries)\n            smape_score.append(smape)\n        \n        else:\n            cl_entries.append(0)\n            smape_score.append(0)\n    \n    weights = np.array(cl_entries) / sum(cl_entries)\n    smape_score_wav = sum(weights * np.array(smape_score))\n    \n    if verbose:\n        for ind, cluster in enumerate(clusters):\n            print(f\"CLUSTER {cluster}:sMAPE: {smape_score[ind]:.4f}, entries: {cl_entries[ind]}\")\n    \n    print(f\"sMAPE weighted average in clusters: {smape_score_wav:.4f}, entries: {sum(cl_entries)}\")\n    \n    return smape_score_wav","metadata":{"execution":{"iopub.status.busy":"2023-05-15T17:37:43.080786Z","iopub.execute_input":"2023-05-15T17:37:43.081115Z","iopub.status.idle":"2023-05-15T17:37:43.094681Z","shell.execute_reply.started":"2023-05-15T17:37:43.081089Z","shell.execute_reply":"2023-05-15T17:37:43.093790Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def predict_clustered_labels_2(df1, df2, df3, df4, clust_nr_list):\n    \n    dfs = (df1.copy(), df2.copy(), df3.copy(), df4.copy())\n    smape_score = []\n    \n    print(\"\\nPREDICTION OF CLUSTERED LABELS\")\n    print(\"=================================================\")\n    \n    for ind, df in enumerate(dfs):\n        print(f\"\\nLABEL: {df.columns[0]}\")\n        smape = predict_clustered_label_2(df, clust_nr_list[ind])\n        smape_score.append(smape)\n        print(\"------------------------------------------------\")\n            \n    y_lengths = np.array([len(dfs[0]), len(dfs[1]), len(dfs[2]), len(dfs[3])])\n    weights = y_lengths / sum(y_lengths)\n    smape_score_wav = sum(weights * np.array(smape_score))\n    \n    print(f\"\\nsMAPE weighted average of labels: {smape_score_wav:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2023-05-15T17:37:43.096229Z","iopub.execute_input":"2023-05-15T17:37:43.096550Z","iopub.status.idle":"2023-05-15T17:37:43.110014Z","shell.execute_reply.started":"2023-05-15T17:37:43.096524Z","shell.execute_reply":"2023-05-15T17:37:43.109162Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"predict_clustered_labels_2(df1, df2, df3, df4, [3, 3, 3, 3])","metadata":{"execution":{"iopub.status.busy":"2023-05-15T17:37:43.110944Z","iopub.execute_input":"2023-05-15T17:37:43.111193Z","iopub.status.idle":"2023-05-15T17:37:50.975575Z","shell.execute_reply.started":"2023-05-15T17:37:43.111174Z","shell.execute_reply":"2023-05-15T17:37:50.974333Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"\nPREDICTION OF CLUSTERED LABELS\n=================================================\n\nLABEL: updrs_1\nCLUSTER 0:sMAPE: 0.0000, entries: 0\nCLUSTER 1:sMAPE: 8.4087, entries: 5\nCLUSTER 2:sMAPE: 56.1417, entries: 844\nsMAPE weighted average in clusters: 55.8606, entries: 849\n------------------------------------------------\n\nLABEL: updrs_2\nCLUSTER 0:sMAPE: 0.0000, entries: 0\nCLUSTER 1:sMAPE: 0.0000, entries: 5\nCLUSTER 2:sMAPE: 93.8219, entries: 844\nsMAPE weighted average in clusters: 93.2694, entries: 849\n------------------------------------------------\n\nLABEL: updrs_3\nCLUSTER 0:sMAPE: 0.0000, entries: 0\nCLUSTER 1:sMAPE: 0.0000, entries: 0\nCLUSTER 2:sMAPE: 77.1141, entries: 823\nsMAPE weighted average in clusters: 77.1141, entries: 823\n------------------------------------------------\n\nLABEL: updrs_4\nCLUSTER 0:sMAPE: 0.0000, entries: 0\nCLUSTER 1:sMAPE: 0.0000, entries: 0\nCLUSTER 2:sMAPE: 145.7780, entries: 448\nsMAPE weighted average in clusters: 145.7780, entries: 448\n------------------------------------------------\n\nsMAPE weighted average of labels: 86.0423\n","output_type":"stream"}]},{"cell_type":"code","source":"predict_clustered_labels_2(df1, df2, df3, df4, [3, 10, 9, 8])","metadata":{"execution":{"iopub.status.busy":"2023-05-15T17:38:19.673486Z","iopub.execute_input":"2023-05-15T17:38:19.673819Z","iopub.status.idle":"2023-05-15T17:38:38.920020Z","shell.execute_reply.started":"2023-05-15T17:38:19.673794Z","shell.execute_reply":"2023-05-15T17:38:38.918474Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"\nPREDICTION OF CLUSTERED LABELS\n=================================================\n\nLABEL: updrs_1\nCLUSTER 0:sMAPE: 0.0000, entries: 0\nCLUSTER 1:sMAPE: 8.4087, entries: 5\nCLUSTER 2:sMAPE: 56.1417, entries: 844\nsMAPE weighted average in clusters: 55.8606, entries: 849\n------------------------------------------------\n\nLABEL: updrs_2\nCLUSTER 0:sMAPE: 0.0000, entries: 0\nCLUSTER 1:sMAPE: 0.0000, entries: 0\nCLUSTER 2:sMAPE: 70.9179, entries: 13\nCLUSTER 3:sMAPE: 101.7297, entries: 11\nCLUSTER 4:sMAPE: 0.0000, entries: 0\nCLUSTER 5:sMAPE: 0.0000, entries: 0\nCLUSTER 6:sMAPE: 0.0000, entries: 0\nCLUSTER 7:sMAPE: 0.0000, entries: 0\nCLUSTER 8:sMAPE: 0.0000, entries: 0\nCLUSTER 9:sMAPE: 93.6238, entries: 775\nsMAPE weighted average in clusters: 93.3659, entries: 799\n------------------------------------------------\n\nLABEL: updrs_3\nCLUSTER 0:sMAPE: 0.0000, entries: 0\nCLUSTER 1:sMAPE: 0.0000, entries: 0\nCLUSTER 2:sMAPE: 0.0000, entries: 0\nCLUSTER 3:sMAPE: 0.0000, entries: 0\nCLUSTER 4:sMAPE: 77.6884, entries: 773\nCLUSTER 5:sMAPE: 0.0000, entries: 0\nCLUSTER 6:sMAPE: 0.0000, entries: 0\nCLUSTER 7:sMAPE: 0.0000, entries: 0\nCLUSTER 8:sMAPE: 0.0000, entries: 0\nsMAPE weighted average in clusters: 77.6884, entries: 773\n------------------------------------------------\n\nLABEL: updrs_4\nCLUSTER 0:sMAPE: 0.0000, entries: 0\nCLUSTER 1:sMAPE: 0.0000, entries: 0\nCLUSTER 2:sMAPE: 0.0000, entries: 0\nCLUSTER 3:sMAPE: 0.0000, entries: 0\nCLUSTER 4:sMAPE: 0.0000, entries: 0\nCLUSTER 5:sMAPE: 0.0000, entries: 0\nCLUSTER 6:sMAPE: 146.1734, entries: 410\nCLUSTER 7:sMAPE: 0.0000, entries: 0\nsMAPE weighted average in clusters: 146.1734, entries: 410\n------------------------------------------------\n\nsMAPE weighted average of labels: 86.2910\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Conclusion:\n### * dimensionality reduction using model LocallyLinearEmbedding gave better results before clusterization than in project 1\n### * improvement of sMAPE due to clusterization was smaller than in project 1, however final result was a little bit better\n### * prediction for evaluation data, related to clusters membership (instead of its re-calculation for merged features), introduced an error of prediction, which affected final sMAPE; it removed a positive impact of clusterization to the final score.","metadata":{}}]}